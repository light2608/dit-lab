# DIT Lab (Working Title)

**DIT Lab** is an openâ€‘source Python framework for simulating artificial â€œbrainsâ€ with superpositionâ€‘like internal states interacting with abstract environments over time. It combines a qubitâ€‘style internal model, a controllable environment, and a 4D lab controller (step, pause, rewind, branch) to study how perception, cognition, and overload evolve under changing conditions.

This repo is intended as a **research playground** for:

- DITâ€‘style *cognitive timelines* (past / present / future zones)  
- Superpositionâ€‘like internal â€œbrainâ€ states (qubitâ€‘inspired)  
- Perception vs reality (what the agent thinks the world is vs what it actually is)  
- Temporal control over cognition (time as an experimental variable)  

---

## âœ¨ Core Ideas

At a high level, DIT Lab is built around four main components:

1. **Environment (`env/`)**  
   A small, controllable abstract world (not necessarily visual/3D at first).  
   Example: a 1D or 2D space with an agent, a threat, noise, light level, etc.

2. **Brain (`brain/`)**  
   An internal state that behaves like a set of â€œqubitsâ€:
   - represented as vectors / amplitudes  
   - evolves via deterministic + stochastic rules  
   - can be â€œmeasuredâ€ to yield a perceived environment and self state  
   
   This is where superposition, entropy and DITâ€‘inspired dynamics live.

3. **LLM Node (`llm/`)**  
   A large language model (external node) that:
   - receives the **true environment** + **brain summary**  
   - returns:
     - suggested updates to internal brain state  
     - a description of **what the brain thinks the environment is**  
   
   The LLM acts as a metaâ€‘controller or â€œnarratorâ€ for cognitive evolution.

4. **4D Lab (`lab/`)**  
   A control layer that:
   - steps the simulation forward  
   - pauses or runs continuously  
   - creates **snapshots** of full state  
   - rewinds to earlier snapshots  
   - branches new timelines from any snapshot  
   
   This turns the simulation into a **timeâ€‘playable lab** for cognition.

---

## ğŸ§± Project Structure

This repository is still in early scaffolding. The following layout shows the intended structure:

```
ditâ€‘lab/
â”œâ”€ pyproject.toml         # or requirements.txt (to be finalised)
â”œâ”€ README.md
â”œâ”€ LICENSE
â”œâ”€ CONTRIBUTING.md        # (planned)
â”œâ”€ docs/
â”‚   â”œâ”€ index.md
â”‚   â””â”€ designâ€‘overview.md
â”œâ”€ examples/
â”‚   â”œâ”€ minimal_cli_demo.py
â”‚   â””â”€ experiment_chaos_vs_stability.py
â”œâ”€ src/
â”‚   â””â”€ ditlab/
â”‚       â”œâ”€ __init__.py
â”‚       â”œâ”€ config/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â””â”€ schemas.py          # pydantic models for configs
â”‚       â”œâ”€ env/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ base.py             # EnvState, BaseEnvironment
â”‚       â”‚   â””â”€ simple_1d.py        # first toy environment
â”‚       â”œâ”€ brain/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ qubits.py           # QubitBrainState and measurement
â”‚       â”‚   â”œâ”€ dynamics.py         # update rules (diffusion, noise)
â”‚       â”‚   â”œâ”€ perception.py       # turning internal state into perception
â”‚       â”‚   â””â”€ metrics.py          # entropy, Î¦â€‘like proxies, divergence
â”‚       â”œâ”€ graphmodel/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â””â”€ task_graph.py       # DIT/task graph representation
â”‚       â”œâ”€ llm/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ client_base.py      # abstract LLM client interface
â”‚       â”‚   â”œâ”€ openai_client.py    # or other providerâ€‘specific impls
â”‚       â”‚   â””â”€ prompts.py          # prompt templates & parsing helpers
â”‚       â”œâ”€ lab/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ state.py            # FullState, serialisable snapshot
â”‚       â”‚   â”œâ”€ timeline.py         # SnapshotManager, branching timelines
â”‚       â”‚   â”œâ”€ controller.py       # main simulation step/run logic
â”‚       â”‚   â””â”€ experiments.py      # helpers for defining experiments
â”‚       â”œâ”€ ui/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ cli.py              # basic CLI
â”‚       â”‚   â””â”€ textual_app.py      # TUI dashboard (planned)
â”‚       â”œâ”€ io/
â”‚       â”‚   â”œâ”€ __init__.py
â”‚       â”‚   â”œâ”€ logging.py          # JSONL / structured logging
â”‚       â”‚   â””â”€ storage.py          # save/load runs, configs, snapshots
â”‚       â””â”€ util/
â”‚           â”œâ”€ __init__.py
â”‚           â””â”€ random_seed.py
â””â”€ tests/
    â”œâ”€ test_env.py
    â”œâ”€ test_brain.py
    â”œâ”€ test_lab.py
    â””â”€ test_llm.py
```

---

## ğŸ› ï¸ Installation (Dev Mode)

> **Note:** This project is in early scaffolding. Expect changes.

```
git clone https://github.com/yourâ€‘username/ditâ€‘lab.git
cd ditâ€‘lab

python -m venv .venv
# Windows:
.\.venv\Scripts\activate
# Mac / Linux:
source .venv/bin/activate

# Temporary: until pyproject.toml is finalised
pip install -r requirements.txt
```

Planned core dependencies:

- `numpy` â€“ vector math, qubit amplitudes  
- `networkx` â€“ DITâ€‘style task / cognitive graphs  
- `pydantic` â€“ clean data models for states/configs  
- `textual` â€“ TUIâ€‘based â€œlab dashboardâ€ (later)  
- `matplotlib` or `plotly` â€“ plots for entropy / Î¦ / metrics  

---

## ğŸš€ Quick Start (Target)

Once the scaffolding is in place, the goal is to support something like:

```
# Run a minimal CLI simulation
python -m ditlab.ui.cli
```

and see:

- true environment state  
- brainâ€™s perceived environment  
- qubit measurements / probabilities  
- step counter, plus options to:
  - `(n)` next step  
  - `(r)` rewind  
  - `(b)` branch  
  - `(q)` quit  

Later, a TUI dashboard (`textual_app.py`) will provide a richer interface with panels and keybindings.

---

## ğŸ“š Background & Inspiration

This project is inspired by the idea of **DIT (Dit Notation)** and **cognitive timelines**:  
modelling cognition as evolving structures across deep past, recent past, present, near future, and speculative future, with integration and overload dynamics.

The goal of DIT Lab is to turn those ideas into an **executable, inspectable simulation**:  
a place where we can stressâ€‘test cognitive architectures, perception models, and temporal control in a small, controlled â€œuniverseâ€.